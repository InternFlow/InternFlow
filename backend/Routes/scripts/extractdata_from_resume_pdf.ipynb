{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5chM97kByzf",
        "outputId": "6c8a8b4d-f989-4f67-8b37-90bdfa9d4f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pdfminer.six in c:\\users\\seif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (20221105)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\seif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pdfminer.six) (3.1.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\seif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pdfminer.six) (40.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\seif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\seif\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
            "[notice] To update, run: C:\\Users\\Seif\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfminer.six\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IJXfMLMfB7o8"
      },
      "outputs": [],
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "text = extract_text('seif.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VQPrm5tfCZg5"
      },
      "outputs": [],
      "source": [
        "extracted_text={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16cw0orMCc3n",
        "outputId": "307739a9-a8fa-496e-e426-5515d438b27e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'spacy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import spacy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n1Taw32rClTS"
      },
      "source": [
        "*Extracting E-mail ID*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99XPbo6MCqSs",
        "outputId": "41ad442f-d379-47c2-b1b5-d7942c066671"
      },
      "outputs": [],
      "source": [
        "match=re.search(r'[\\w\\.-]+@[\\w\\.-]+',text)\n",
        "match.group(0)#E-MAIL\n",
        "import re\n",
        "def get_email_addresses(string):\n",
        "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
        "    return r.findall(string)\n",
        "\n",
        "email = get_email_addresses(text)\n",
        "print(email)\n",
        "extracted_text['E-mail'] = email"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5OC-XefoCx84"
      },
      "source": [
        "*Extracting Phone Number*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THALA_9dC1AS",
        "outputId": "dca6c7ed-c7f1-40ce-b6d7-c19e2f33038c"
      },
      "outputs": [],
      "source": [
        "def get_phone_numbers(string):\n",
        "    r = re.compile(r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})')\n",
        "    phone_numbers = r.findall(string)\n",
        "    return [re.sub(r'\\D', '', num) for num in phone_numbers]\n",
        "\n",
        "phone_number= get_phone_numbers(text)\n",
        "print(phone_number)\n",
        "extracted_text['Phone number'] = phone_number"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2P5XuVpEC95u"
      },
      "source": [
        "*Extracting Name*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMejSkZfDBzP",
        "outputId": "2f44f024-1733-4ce7-f8ab-e37d06d3fbb2"
      },
      "outputs": [],
      "source": [
        "from spacy.matcher import Matcher\n",
        "\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# initialize matcher with a vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "def extract_name(resume_text):\n",
        "  nlp_text = nlp(resume_text)\n",
        "  # First name and Last name are always Proper Nouns\n",
        "  pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "  \n",
        "  matcher.add('NAME', [pattern], on_match=None)\n",
        "  \n",
        "  matches = matcher(nlp_text)\n",
        "  \n",
        "  for match_id, start, end in matches:\n",
        "    span = nlp_text[start:end]\n",
        "    return span.text\n",
        "\n",
        "name = extract_name(text)\n",
        "print(name)\n",
        "extracted_text['Name'] = name    \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "i29juGMoDtt-"
      },
      "source": [
        "*Extracting Skills*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sxPcgR0DxPV"
      },
      "outputs": [],
      "source": [
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_skills(resume_text):\n",
        "  nlp_text = nlp(resume_text)\n",
        "  \n",
        "  # removing stop words and implementing word tokenization\n",
        "  tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "\n",
        "  skills = [\"HTML\", \"CSS\", \"PHP\", \"MongoDB\", \"ReactJS\", \"SQL\", \"MSQL\", \"Github\", \"Springboot\", \"AngularJS\", \"ai\", \"Django\", \"Pyhton\"]\n",
        "\n",
        "  skillset = []\n",
        "  \n",
        "  # check for one-grams (example: python)\n",
        "  for token in tokens:\n",
        "    if token.lower() in skills:\n",
        "      skillset.append(token)\n",
        "\n",
        "  # check for bi-grams and tri-grams (example: machine learning)\n",
        "  for token in nlp_text.noun_chunks:\n",
        "    token = token.text.lower().strip()\n",
        "    if token in skills:\n",
        "      skillset.append(token)  \n",
        "  return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
        "\n",
        "extracted_text['Skills'] = extract_skills(text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zo-ugTKaFgRW"
      },
      "source": [
        "*Extracting Degree*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umXKyPraFjtG"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Grad all general stop words\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Education Degrees\n",
        "Degree = [\n",
        "            'BE','B.E.', 'B.E', 'BS', 'B.S','C.A.','c.a.','B.Com','B. Com',\n",
        "            'M. Com', 'M.Com','M. Com .',\n",
        "            'ME', 'M.E', 'M.E.', 'MS', 'M.S',\n",
        "            'BTECH', 'B.TECH', 'M.TECH', 'MTECH',\n",
        "            'PHD', 'phd', 'ph.d', 'Ph.D.','MBA','mba',\n",
        "            'graduate', 'post-graduate','5 year integrated masters','masters',\n",
        "            'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII', 'engineer'\n",
        "        ]\n",
        "\n",
        "def extract_degree(resume_text):\n",
        "  nlp_text = nlp(resume_text)\n",
        "  \n",
        "  # Sentence Tokenizer\n",
        "  nlp_text = [sent.text.strip() for sent in nlp_text.sents]\n",
        "  \n",
        "  edu = {}\n",
        "  # Extract education degree\n",
        "  for index, text in enumerate(nlp_text):\n",
        "    for tex in text.split():\n",
        "      # Replace all special symbols\n",
        "      tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
        "      if tex.upper() in Degree and tex not in STOPWORDS:\n",
        "        edu[tex] = text + nlp_text[index + 1]\n",
        "\n",
        "  # Extract year\n",
        "  education = []\n",
        "  for key in edu.keys():\n",
        "    year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
        "    if year:\n",
        "      education.append((key, ''.join(year[0])))\n",
        "    else:\n",
        "      education.append(key)\n",
        "  return education\n",
        "\n",
        "extract_degree(text)\n",
        "extracted_text['Degree'] = extract_degree(text)\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-BCSEhFnHupF"
      },
      "source": [
        "*Extracting University/College*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9rHUf_7Hx8j"
      },
      "outputs": [],
      "source": [
        "sub_patterns = ['[A-Z][a-z]* [A-Z][a-z]* University','[A-Z][a-z]* Educational Institute','[A-Z][a-z]* University',\n",
        "                'University of [A-Z][a-z]* [A-Z][a-z]*', 'University of [A-Z][a-z]*',\n",
        "                'Ecole [A-Z][a-z]* [A-Z][a-z]*']\n",
        "pattern = '({})'.format('|'.join(sub_patterns))\n",
        "education = re.findall(pattern, text)\n",
        "extracted_text['Education'] = education"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A-jXgCrPH5Zw"
      },
      "source": [
        "*Extracting Experience*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mfQGOlCIH_F"
      },
      "outputs": [],
      "source": [
        "sub_patterns = ['[A-Z][a-z]* [A-Z][a-z]* Pvt. Ltd.','[A-Z][a-z]* [A-Z][a-z]* Private Limited', '[A-Z][a-z]* LLC',\n",
        "                '[A-Z][a-z]* Pvt. Ltd.', '[A-Z][a-z]* Private Limited', '[A-Z][a-z]* [A-Z][a-z]* [A-Z][a-z]* Pvt. Ltd.']\n",
        "pattern = '({})'.format('|'.join(sub_patterns))\n",
        "experience = re.findall(pattern, text)\n",
        "extracted_text['Experience'] = experience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l83WspTIQWl",
        "outputId": "129c9a77-d2a5-4a8f-c219-e6dbf36affb7"
      },
      "outputs": [],
      "source": [
        "print(extracted_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyony8sBIWMf",
        "outputId": "dc9c1b76-a6ed-4f83-dc5e-ab1742287dd5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# Serializing json \n",
        "json_object = json.dumps(extracted_text, indent =8)\n",
        "  \n",
        "# Writing to sample.json\n",
        "with open(\"sample.json\", \"w\") as outfile:\n",
        "    outfile.write(json_object)\n",
        "    \n",
        "\n",
        "print(json_object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBj8-FoOIe_t"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
